# Implement new model architectures

# -> Implement groundbreaking transformer model

# Find and include all datasets
    # These include:
        - ENST and MDB 1.0+2.0, together as small dataset
        - Slakh
        - EGMD
        - ADTOF-YT (already included)
    
    # Parse them correctly, get same formatted output

# Perform training and testing over several datasets

# Create analysis notebooks for model performance and plotting


# Questions:

    - When doing architecture performance comparisons, compare using test scores?

    - When doing cross-dataset prediction, use normalization constants from training dataset (trained on)?

    - Preprocessing, like the spectrograms and fft? Should be mentioned in background or methods?

    - When talking about datasets, how to differentiate existing with my? What goes under methods, what doesn't. Something in both?


# Todos for thesis: 

    ---
    Remember to distinguish what has been done before.
    Be clear when saying "I've combined these techniques which have been done before".
    Distinguish own novel contributions with previous ones.

    Background should include a lot more information from methodology.
        - The task should be explained here
        - Explaining the spectrogram/mel-spectrogram, input data and labels
        - The postprocessing, peak-picking algorithm should be here
        - Everything about performance measures should be here
        - Maybe something about previous architectures here aswell
    
    Methods should explain what I've done, not necessarily why or where stuff comes from.
    

    Sort in order of experiments after methods:
    Methods -> Experiment 1 (Method -> Result -> Discussion) -> Experiment 2 (Method -> Result -> Discussion) -> Experiment 3? -> Conclusion