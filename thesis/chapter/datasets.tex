\chapter{Datasets}

\section{ENST+MDB}

The ENST-Drums dataset by Gillet et al.~\cite{gillet_2006_7432188} has been one of the most commonly used \gls{ADT} datasets~\cite{8350302}. It features thorougly annotated drum samples by three drummers over different musical genres. Most of the tracks contain drum-only recordings, except the \textit{minus-one} subset, which is played together with a music accompaniement. As this thesis attends to \gls{DTM} tasks, we isolate our focus to this subset of tracks.

As this dataset contains separate audio files for performance and accompaniement, we additively combine them to create a singular respective mixture track.

\textcolor{red}{Explain how many samples + total duration of this dataset.}

Another well-known MedleyDB Drums dataset, from Southall et al.~\cite{southall2017mdb}. This dataset is built on top of Bittner et al.'s MedleyDB dataset~\cite{rachel_bittner_2014_1438309}, but re-annotated and specialized for \gls{ADT} related tasks.

\textcolor{red}{Explain how many samples + total duration of this dataset too.}

Both of these datasets distributes their audio in waveform files, and their annotations in text files. Annotations are formatted by onset time and instrument label. They are also relatively small, and contain thorough, real, annotated data.Due to these similarities, in this thesis they are combined together into a slightly larger ENST+MDB dataset.

\subsection{Splits}

\textcolor{red}{Explain how this dataset gets train/val/test split.}

\subsection{Mapping}

\textcolor{red}{Maybe (or maybe not) explain the mapping from this to 5-instrument mapping.}

\section{EMG-D}

\section{Slakh}

\section{ADTOF-YT}

\section{SADTP}

The SADTP (Small Automatic Drum Transcription Performance) dataset is a novel dataset introduced in this thesis. It is a small dataset comprised of 16 songs with corresponding MIDI transcriptions. The \textit{performance} name alludes to the transcription being recorded live while listening to the songs on playback, with only minor post-processing. The transcriptions were recorded on a Roland TD-11 electric drumset, recording the MIDI perfomance to Apple's Garageband, and extracting them to separate MIDI files.

The dataset contains 1.08 hours of music, which can be split into 977 non-overlapping 4 second datapoints (includes zero padding certain pieces for even partitioning).