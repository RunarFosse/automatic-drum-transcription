\chapter{Architecture Study}

This study's main purpose is to figure out how suited each architecture is for \gls{ADT}, more specifically \gls{DTM} tasks. This could help us figure out which architecture is superiour for \gls{ADT}, if there are any similarities between architectures who perform similarly well, or if there are any architectures who perform poorly.

\section{Methodology}

We perform hyperparameter tuning and model selection to train a separate model for each architecture over each dataset. At last we test the model on each dataset's respective test split. As a result, we are left with performance measures on unseen data from the same distribution as those each model was train on. This will give us a good intuition into each architecture's ability to learn the task of \gls{ADT} and could help us estimate their generalization ability.

\section{Results}

\begin{center}
    \begin{tabular}{|l|c|c|c|c|}
    \hline
                   & ENST+MDB & E-GMD & Slakh & ADTOF-YT \\
    \hline
    Recurrent &       & 0.8892          & 0.8502          & 0.9498          \\
    Convolutional &       & 0.8657          & 0.8305          & 0.8290          \\
    Convolutional Recurrent &       & \textbf{0.8911}          & \textbf{0.8914}          & 0.9455          \\
    Convolutional Transformer &        & 0.8852          & 0.8828          & 0.9533          \\
    Vision Transformer &       & 0.8818          & 0.8755          & \textbf{0.9560}         \\   
    \hline

    \end{tabular}
\end{center}		

\textcolor{red}{Display the results in a barplot, to easily capture well-performing models.}

\section{Discussion}

As we can see...