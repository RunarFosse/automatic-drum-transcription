\chapter{Architecture Study}

This study's main purpose is to figure out how suited each architecture is for \gls{ADT}, more specifically \gls{DTM} tasks. This could help us figure out which architecture is superior for \gls{ADT}, if there are any similarities between architectures who perform similarly well, or if there are any architectures who perform poorly.

\section{Methodology}

We perform hyperparameter tuning and model selection to train a separate model for each architecture over each dataset. At last we test the model on each dataset's respective test split. As a result, we are left with performance measures on unseen data from the same distribution as those each model was train on. This will give us a good intuition into each architecture's ability to learn the task of \gls{ADT} and could help us estimate their generalization ability.

\section{Results}	

\begin{table}[H]
    \centering
    \hspace*{-0.6cm}
    \begin{tabular}{l|cccc}
        Architecture & ENST+MDB & E-GMD & Slakh & ADTOF-YT       \\
        \hline
        Recurrent Neural Network	& 0.6682 &	0.889 &	0.864 &	\textbf{0.9635} \\
        Convolutional Neural Network	& 0.7797 &	0.8744 &	0.8318 &	0.844 \\
        Convolutional Recurrent Neural Network	& \textbf{0.8132} &	\textbf{0.8935} &	\textbf{0.8959} &	0.9333 \\
        Convolutional Transformer	& 0.776 &	0.8831 &	0.8826 &	0.9535 \\
        Vision Transformer	& 0.5426 &	0.8779 &	0.879 &	\textbf{0.9635} \\
        
    \end{tabular}
    \caption{The Micro F1-score for each architecture, trained and tested on each dataset. The performances which are bolded represent the highest F1-score, and thus best performance, for that respective dataset.}
    \label{ArchitectureResultsTable}
\end{table}


\begin{figure}[H]
    \centering
    \hspace*{-0.8cm}
    \includegraphics[scale=0.8]{figures/architectureperformancearchitecture.png}
    \caption{Comparison of Micro F1-scores for each dataset across the different architectures. Bars marked with a ($\star$) indicate the best performing architecture for each respective dataset.}
    \label{ArchitectureResultsArchitectureFigure}
\end{figure}

\begin{figure}[H]
    \centering
    \hspace*{-0.8cm}
    \includegraphics[scale=0.8]{figures/architectureperformancedataset.png}
    \caption{Comparison of Micro F1-scores for each architectures across the different dataset. Bars marked with a ($\star$) indicate the best performing architecture for each respective dataset.}
    \label{ArchitectureResultsDatasetFigure}
\end{figure}

\section{Discussion}

The architecture study's results are summarized in Table \ref{ArchitectureResultsTable} and visualized in Figures \ref{ArchitectureResultsArchitectureFigure} and \ref{ArchitectureResultsDatasetFigure}. From these results we can compare and discuss how each model performs, and speculate where the sources of their performances lie.

Firstly, it is evident that there does not seem to be one superior architecture when it comes to \gls{ADT}. There does not exist a single architecture outperforming the others across all the datasets, and the different architectures often share similarly high performances on most of the datasets. 

However, the convolutional recurrent neural network demonstrates the highest Micro F1-score on three of the four datasets (namely ENST+MDB, E-GMD and Slakh). It also provides a high, but not exceptional F1-score on the fourth (ADTOF-YT). The consistency of its high performance across the different properties of each dataset suggests that it is able to handle a wide variety of \gls{ADT} tasks, and that its performance may be high independent on the training dataset's size and complexity. In other words, it displays properties of being a architecture highly suitable for \gls{ADT} tasks. One could speculate that this suitability is provided by the strong inductive bias from the combination of convolutions and recurrent units, allowing for both initial spatial feature extraction as well as short-time temporal modelling.

The convolutional neural network displays a moderate performance across all datasets. It shows adequate performance on the smallest dataset (ENST+MDB), having the second highest F1-score. However, across all others (E-GMD, Slakh and ADTOF-YT) it displays the lowest. This relatively poor overall performance seems to indicate that the convolutional neural network currently is an inferior architecture for \gls{ADT} tasks, unless dataset size is limited, in which it could provide a viable architecture. It also shows the importance of explicitly leveraging the temporal dependencies within \gls{ADT}, as solely relying on the inductive bias of the convolutions didn't prove sufficient here.

This importance seems to be strengthened by the performance of the purely recurrent neural network, which has a surprisingly high performance across the datasets. In a way, it displays the opposite behaviour compared to the \gls{CNN}, displaying inadequate performance for the smallest dataset (ENST+MDB), but a relatively high performance for two of the others (E-GMD and Slakh), sharing the crown for the highest F1-score on the last (ADTOF-YT). The first dataset's low performance suggests that the inductive bias of the recurrent layers are "weaker" than the ones from convolutions, relying on a larger amount of data to accurately learn the task. Notably, it significantly outperforms the \gls{CRNN} on the last dataset, hinting that the inductive bias of the convolutions might "overpower" the model, proving so strong that it pulls the performance of the model down.

