\chapter{Introduction}

Within the field of \gls{MIR}, the task of \gls{AMT} is considered to be, both an important, and challenging research problem. It describes the process of generating a symbolic notation from audio. The majority of instruments are melodic, where key information for transcription would be to discern pitch, onset time, and duration. This stands in contrast to percussive instruments, where instead of pitch and duration one would focus on instrument classification and onset detection. This sets the stage for \gls{ADT}, which is a subfield of \gls{AMT}, specifically focusing on drums and percussive instruments.~\cite{8350302}

Previously, a popular approach to \gls{ADT} was using signal processing, which later developed into using classical machine learning methods~\cite{8350302}. However in later years, deep learning has shown to be quite effective. Therfore, the recent focus of most authors has been to find the best performing deep learning approaches by either; constructing and analysing the best performing model architectures, or by finding datasets which allow models to generalize the best.~\cite{signals4040042}

\textcolor{red}{Provide a good introduction into the master thesis, mentioning \gls{AMT}, \gls{ADT} and why deep learning is suited for such a task.}

\textcolor{red}{Also shortly mention how we represent the sound, and the transcriptions. What is/how do we do \gls{ADT}}

\section{Thesis statement}

This leads us to two primary questions. Which deep learning architecture is the best suited for solving a task like this? And, what makes a dataset optimal by making models generalize? These are two of the questions we will try to answer in this thesis. 

For the former, we will train different model architectures on different, well-known \gls{ADT} datasets. Specifically, recurrent neural networks, convolutional neural networks, convolutional-recurrent neural networks, convolutional transformers and vision transformers. By comparing their performances we could be able to gauge the one best suited for an \gls{ADT} task.

For the latter, we will select the best performing model architecture from the first question, and train it over several different combination of the \gls{ADT} datasets. By performing zero-shot evaluations, we could analyse and figure out what makes a good \gls{ADT} dataset and how it would supplement a suitable model architecture.

In addition to these, we will also analyse two standard approaches when it comes to \gls{ADT} and see how effective they really are, through ablation studies. These are, usage of log-filtered spectrograms, and frequency-based, dynamic timestep loss-weighting during training. 

\textcolor{red}{
    Present the aim of the thesis here. And the \b{questions!}
How do we train a model capable of solving such a task at a high performing level. More specifically:
}


\textcolor{red}{
What architectures are suited for learning such a task?
What datasets / combination of datasets makes the model generalize best?
Of the many techniques made to help models learn this task, which ones actually help? (Ablation)
}

\textcolor{red}{\textbf{Remember the concrete \underline{What do we want to figure out}.}}