@INPROCEEDINGS{8937170,
  author={Manilow, Ethan and Wichern, Gordon and Seetharaman, Prem and Le Roux, Jonathan},
  booktitle={2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}, 
  title={Cutting Music Source Separation Some Slakh: A Dataset to Study the Impact of Training Data Quality and Quantity}, 
  year={2019},
  volume={},
  number={},
  pages={45-49},
  keywords={Training;Source separation;Instruments;Training data;Music;Tools;Multiple signal classification;music source separation;sample-based virtual instruments;synthesis;MIDI},
  doi={10.1109/WASPAA.2019.8937170}}

@book{raffel2016learning,
  title={Learning-based methods for comparing sequences, with applications to audio-to-midi alignment and matching},
  author={Raffel, Colin},
  year={2016},
  publisher={Columbia University}
}


@misc{callender2020improving,
    title={Improving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset},
    author={Lee Callender and Curtis Hawthorne and Jesse Engel},
    year={2020},
    eprint={2004.00188},
    archivePrefix={arXiv},
    primaryClass={cs.SD}
}

@misc{vogl2018multiinstrumentdrumtranscription,
      title={Towards multi-instrument drum transcription}, 
      author={Richard Vogl and Gerhard Widmer and Peter Knees},
      year={2018},
      eprint={1806.06676},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1806.06676}, 
}

@article{8350302,
  author={Wu, Chih-Wei and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason and Müller, Meinard and Lerch, Alexander},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={A Review of Automatic Drum Transcription}, 
  year={2018},
  volume={26},
  number={9},
  pages={1457-1483},
  keywords={Instruments;Task analysis;Speech processing;Spectrogram;Transient analysis;Rhythm;Music information retrieval;automatic music transcription;automatic drum transcription;machine learning;matrix factorization;deep learning},
  doi={10.1109/TASLP.2018.2830113}
}


@Article{signals4040042,
AUTHOR = {Zehren, Mickaël and Alunno, Marco and Bientinesi, Paolo},
TITLE = {High-Quality and Reproducible Automatic Drum Transcription from Crowdsourced Data},
JOURNAL = {Signals},
VOLUME = {4},
YEAR = {2023},
NUMBER = {4},
PAGES = {768--787},
URL = {https://www.mdpi.com/2624-6120/4/4/42},
ISSN = {2624-6120},
ABSTRACT = {Within the broad problem known as automatic music transcription, we considered the specific task of automatic drum transcription (ADT). This is a complex task that has recently shown significant advances thanks to deep learning (DL) techniques. Most notably, massive amounts of labeled data obtained from crowds of annotators have made it possible to implement large-scale supervised learning architectures for ADT. In this study, we explored the untapped potential of these new datasets by addressing three key points: First, we reviewed recent trends in DL architectures and focused on two techniques, self-attention mechanisms and tatum-synchronous convolutions. Then, to mitigate the noise and bias that are inherent in crowdsourced data, we extended the training data with additional annotations. Finally, to quantify the potential of the data, we compared many training scenarios by combining up to six different datasets, including zero-shot evaluations. Our findings revealed that crowdsourced datasets outperform previously utilized datasets, and regardless of the DL architecture employed, they are sufficient in size and quality to train accurate models. By fully exploiting this data source, our models produced high-quality drum transcriptions, achieving state-of-the-art results. Thanks to this accuracy, our work can be more successfully used by musicians (e.g., to learn new musical pieces by reading, or to convert their performances to MIDI) and researchers in music information retrieval (e.g., to retrieve information from the notes instead of audio, such as the rhythm or structure of a piece).},
DOI = {10.3390/signals4040042}
}

@inproceedings{Vogl2017DrumTV,
  title={Drum Transcription via Joint Beat and Drum Modeling Using Convolutional Recurrent Neural Networks},
  author={Richard Vogl and Matthias Dorfer and Gerhard Widmer and Peter Knees},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:21314796}
}

@misc{zehren2024analyzingreducingsynthetictorealtransfer,
      title={Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription}, 
      author={Mickaël Zehren and Marco Alunno and Paolo Bientinesi},
      year={2024},
      eprint={2407.19823},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2407.19823}, 
}

@misc{chang2024yourmt3multiinstrumentmusictranscription,
      title={YourMT3+: Multi-instrument Music Transcription with Enhanced Transformer Architectures and Cross-dataset Stem Augmentation}, 
      author={Sungkyun Chang and Emmanouil Benetos and Holger Kirchhoff and Simon Dixon},
      year={2024},
      eprint={2407.04822},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2407.04822}, 
}

@book{1953fundamentals,
  title={Fundamentals of Telephony},
  url={https://books.google.no/books?id=8nvJ6qvtdPUC},
  year={1953},
  publisher={United States, Department of the Army}
}

@article{8454362,
  author={Chakravorty, Pragnan},
  journal={IEEE Signal Processing Magazine}, 
  title={What Is a Signal? [Lecture Notes]}, 
  year={2018},
  volume={35},
  number={5},
  pages={175-177},
  keywords={Signal processing;Antenna arrays;Spread spectrum communication;Image color analysis;Task analysis},
  doi={10.1109/MSP.2018.2832195}
}

@misc{oord2016wavenetgenerativemodelraw,
      title={WaveNet: A Generative Model for Raw Audio}, 
      author={Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
      year={2016},
      eprint={1609.03499},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1609.03499}, 
}

@dataset{gillet_2006_7432188,
  author       = {Gillet, Olivier and
                  Richard, Gaël},
  title        = {ENST-Drums: an extensive audio-visual database for
                   drum signals processing
                  },
  month        = oct,
  year         = 2006,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.7432188},
  url          = {https://doi.org/10.5281/zenodo.7432188},
}

@article{southall2017mdb,
  title={MDB Drums: An annotated subset of MedleyDB for automatic drum transcription},
  author={Southall, Carl and Wu, Chih-Wei and Lerch, Alexander and Hockman, Jason},
  year={2017}
}

@dataset{rachel_bittner_2014_1438309,
  author       = {Rachel Bittner and
                  Justin Salamon and
                  Mike Tierney and
                  Matthias Mauch and
                  Chris Cannam and
                  Juan Pablo Bello},
  title        = {MedleyDB Sample},
  month        = oct,
  year         = 2014,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.1438309},
  url          = {https://doi.org/10.5281/zenodo.1438309},
}

@article{pras2010sampling,
author={Pras Amandine and Guastavino Catherine},
journal={Journal of the Audio Engineering Society},
title={Sampling rate discrimination: 44.1 khz vs. 88.2 khz},
year={2010},
number={8101},
month={may},}

@misc{strang1993wavelettransformsversusfourier,
      title={Wavelet transforms versus Fourier transforms}, 
      author={Gilbert Strang},
      year={1993},
      eprint={math/9304214},
      archivePrefix={arXiv},
      primaryClass={math.NA},
      url={https://arxiv.org/abs/math/9304214}, 
}

@article{d3ea2d52-5ab2-3128-8b80-efb85267295d,
 ISSN = {00255718, 10886842},
 URL = {http://www.jstor.org/stable/2003354},
 author = {James W. Cooley and John W. Tukey},
 journal = {Mathematics of Computation},
 number = {90},
 pages = {297--301},
 publisher = {American Mathematical Society},
 title = {An Algorithm for the Machine Calculation of Complex Fourier Series},
 urldate = {2025-04-01},
 volume = {19},
 year = {1965}
}

@ARTICLE{1164317,
  author={Griffin, D. and Jae Lim},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Signal estimation from modified short-time Fourier transform}, 
  year={1984},
  volume={32},
  number={2},
  pages={236-243},
  keywords={Fourier transforms;Iterative algorithms;Discrete Fourier transforms;Speech enhancement;Hardware;Signal processing;Degradation;Estimation theory;Monitoring;Sampling methods},
  doi={10.1109/TASSP.1984.1164317}}

@article{5c874280-b9b4-3490-886e-70aef7a6c0f2,
 ISSN = {00222909},
 URL = {http://www.jstor.org/stable/843164},
 author = {Paul Pedersen},
 journal = {Journal of Music Theory},
 number = {2},
 pages = {295--308},
 publisher = {[Duke University Press, Yale University Department of Music]},
 title = {The Mel Scale},
 urldate = {2025-04-02},
 volume = {9},
 year = {1965}
}

@misc{wolfmonheim2024spectralrhythmfeaturesaudio,
      title={Spectral and Rhythm Features for Audio Classification with Deep Convolutional Neural Networks}, 
      author={Friedrich Wolf-Monheim},
      year={2024},
      eprint={2410.06927},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2410.06927}, 
}

@misc{gardner2022mt3multitaskmultitrackmusic,
      title={MT3: Multi-Task Multitrack Music Transcription}, 
      author={Josh Gardner and Ian Simon and Ethan Manilow and Curtis Hawthorne and Jesse Engel},
      year={2022},
      eprint={2111.03017},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2111.03017}, 
}

@misc{gong2021astaudiospectrogramtransformer,
      title={AST: Audio Spectrogram Transformer}, 
      author={Yuan Gong and Yu-An Chung and James Glass},
      year={2021},
      eprint={2104.01778},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2104.01778}, 
}

@inproceedings{Southall2016AutomaticDT,
  title={Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks},
  author={Carl Southall and Ryan Stables and Jason Hockman},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:2891003}
}

@inproceedings{inproceedings,
author = {Vogl, Richard and Dorfer, Matthias and Knees, Peter},
year = {2016},
month = {08},
pages = {},
title = {Recurrent Neural Networks for Drum Transcription}
}

@inproceedings{Bck2012EvaluatingTO,
  title={Evaluating the Online Capabilities of Onset Detection Methods},
  author={Sebastian B{\"o}ck and Florian Krebs and Markus Schedl},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:7379180}
}

@book{TheDrumHandbook2003,
  author = {Nicholls, Geoff},
  editor = {},
  publisher = {San Francisco, CA: Backbeat Books},
  title = {The Drum Handbook: Buying, maintaining, and getting the best from your drum kit},
  year = {2003}
}

@article{10.1162/neco.1997.9.8.1735,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{DBLP:conf/emnlp/ChoMGBBSB14,
  author       = {Kyunghyun Cho and
                  Bart van Merrienboer and
                  {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
                  Dzmitry Bahdanau and
                  Fethi Bougares and
                  Holger Schwenk and
                  Yoshua Bengio},
  editor       = {Alessandro Moschitti and
                  Bo Pang and
                  Walter Daelemans},
  title        = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
                  Machine Translation},
  booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2014, October 25-29, 2014, Doha, Qatar,
                  {A} meeting of SIGDAT, a Special Interest Group of the {ACL}},
  pages        = {1724--1734},
  publisher    = {{ACL}},
  year         = {2014},
  url          = {https://doi.org/10.3115/v1/d14-1179},
  doi          = {10.3115/V1/D14-1179},
  timestamp    = {Sun, 06 Oct 2024 21:00:49 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/ChoMGBBSB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{gulati2020conformerconvolutionaugmentedtransformerspeech,
      title={Conformer: Convolution-augmented Transformer for Speech Recognition}, 
      author={Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
      year={2020},
      eprint={2005.08100},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2005.08100}, 
}


@InProceedings{pmlr-v119-xiong20b,
  title = 	 {On Layer Normalization in the Transformer Architecture},
  author =       {Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10524--10533},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf},
  url = 	 {https://proceedings.mlr.press/v119/xiong20b.html},
  abstract = 	 {The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}

@misc{hendrycks2023gaussianerrorlinearunits,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.08415}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}


@InProceedings{pmlr-v97-gillick19a,
  title = 	 {Learning to Groove with Inverse Sequence Transformations},
  author =       {Gillick, Jon and Roberts, Adam and Engel, Jesse and Eck, Douglas and Bamman, David},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2269--2279},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/gillick19a/gillick19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/gillick19a.html},
  abstract = 	 {We explore models for translating abstract musical ideas (scores, rhythms) into expressive performances using seq2seq and recurrent variational information bottleneck (VIB) models. Though seq2seq models usually require painstakingly aligned corpora, we show that it is possible to adapt an approach from the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix, Vid2Vid) to sequences, creating large volumes of paired data by performing simple transformations and training generative models to plausibly invert these transformations. Music, and drumming in particular, provides a strong test case for this approach because many common transformations (quantization, removing voices) have clear semantics, and learning to invert them has real-world applications. Focusing on the case of drum set players, we create and release a new dataset for this purpose, containing over 13 hours of recordings by professional drummers aligned with fine-grained timing and dynamics information. We also explore some of the creative potential of these models, demonstrating improvements on state-of-the-art methods for Humanization (instantiating a performance from a musical score).}
}

@mastersthesis{holz2021automatic,
  title={Automatic drum transcription with deep neural networks},
  author={Holz, Thomas},
  year={2021},
  school={Technische Universitaet Berlin (Germany)}
}

@INPROCEEDINGS{9747048,
  author={Hung, Yun-Ning and Wang, Ju-Chiang and Song, Xuchen and Lu, Wei-Tsung and Won, Minz},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Modeling Beats and Downbeats with a Time-Frequency Transformer}, 
  year={2022},
  volume={},
  number={},
  pages={401-405},
  keywords={Deep learning;Time-frequency analysis;Convolution;Neural networks;Transformers;Harmonic analysis;Natural language processing;Beat;Downbeat;Transformer;SpecTNT},
  doi={10.1109/ICASSP43922.2022.9747048}}

@ARTICLE{10056354,
  author={Huang, Lei and Qin, Jie and Zhou, Yi and Zhu, Fan and Liu, Li and Shao, Ling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Normalization Techniques in Training DNNs: Methodology, Analysis and Application}, 
  year={2023},
  volume={45},
  number={8},
  pages={10173-10196},
  keywords={Training;Optimization;Covariance matrices;Task analysis;Tensors;Decorrelation;Biological neural networks;Batch normalization;deep neural networks;image classification;survey;weight normalization},
  doi={10.1109/TPAMI.2023.3250241}}

@inproceedings{cartwright2018increasing,
  title={Increasing drum transcription vocabulary using data synthesis},
  author={Cartwright, Mark and Bello, Juan Pablo},
  booktitle={Proc. International Conference on Digital Audio Effects (DAFx)},
  pages={72--79},
  year={2018}
}