@inproceedings{manilow2019cutting,
  title={Cutting Music Source Separation Some {Slakh}: A Dataset to Study the Impact of Training Data Quality and Quantity},
  author={Manilow, Ethan and Wichern, Gordon and Seetharaman, Prem and Le Roux, Jonathan},
  booktitle={Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
  year={2019},
  organization={IEEE}
}

@misc{callender2020improving,
    title={Improving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset},
    author={Lee Callender and Curtis Hawthorne and Jesse Engel},
    year={2020},
    eprint={2004.00188},
    archivePrefix={arXiv},
    primaryClass={cs.SD}
}

@misc{vogl2018multiinstrumentdrumtranscription,
      title={Towards multi-instrument drum transcription}, 
      author={Richard Vogl and Gerhard Widmer and Peter Knees},
      year={2018},
      eprint={1806.06676},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1806.06676}, 
}

@article{8350302,
  author={Wu, Chih-Wei and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason and Müller, Meinard and Lerch, Alexander},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={A Review of Automatic Drum Transcription}, 
  year={2018},
  volume={26},
  number={9},
  pages={1457-1483},
  keywords={Instruments;Task analysis;Speech processing;Spectrogram;Transient analysis;Rhythm;Music information retrieval;automatic music transcription;automatic drum transcription;machine learning;matrix factorization;deep learning},
  doi={10.1109/TASLP.2018.2830113}
}


@Article{signals4040042,
AUTHOR = {Zehren, Mickaël and Alunno, Marco and Bientinesi, Paolo},
TITLE = {High-Quality and Reproducible Automatic Drum Transcription from Crowdsourced Data},
JOURNAL = {Signals},
VOLUME = {4},
YEAR = {2023},
NUMBER = {4},
PAGES = {768--787},
URL = {https://www.mdpi.com/2624-6120/4/4/42},
ISSN = {2624-6120},
ABSTRACT = {Within the broad problem known as automatic music transcription, we considered the specific task of automatic drum transcription (ADT). This is a complex task that has recently shown significant advances thanks to deep learning (DL) techniques. Most notably, massive amounts of labeled data obtained from crowds of annotators have made it possible to implement large-scale supervised learning architectures for ADT. In this study, we explored the untapped potential of these new datasets by addressing three key points: First, we reviewed recent trends in DL architectures and focused on two techniques, self-attention mechanisms and tatum-synchronous convolutions. Then, to mitigate the noise and bias that are inherent in crowdsourced data, we extended the training data with additional annotations. Finally, to quantify the potential of the data, we compared many training scenarios by combining up to six different datasets, including zero-shot evaluations. Our findings revealed that crowdsourced datasets outperform previously utilized datasets, and regardless of the DL architecture employed, they are sufficient in size and quality to train accurate models. By fully exploiting this data source, our models produced high-quality drum transcriptions, achieving state-of-the-art results. Thanks to this accuracy, our work can be more successfully used by musicians (e.g., to learn new musical pieces by reading, or to convert their performances to MIDI) and researchers in music information retrieval (e.g., to retrieve information from the notes instead of audio, such as the rhythm or structure of a piece).},
DOI = {10.3390/signals4040042}
}

@inproceedings{Vogl2017DrumTV,
  title={Drum Transcription via Joint Beat and Drum Modeling Using Convolutional Recurrent Neural Networks},
  author={Richard Vogl and Matthias Dorfer and Gerhard Widmer and Peter Knees},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:21314796}
}

@misc{zehren2024analyzingreducingsynthetictorealtransfer,
      title={Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription}, 
      author={Mickaël Zehren and Marco Alunno and Paolo Bientinesi},
      year={2024},
      eprint={2407.19823},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2407.19823}, 
}

@misc{chang2024yourmt3multiinstrumentmusictranscription,
      title={YourMT3+: Multi-instrument Music Transcription with Enhanced Transformer Architectures and Cross-dataset Stem Augmentation}, 
      author={Sungkyun Chang and Emmanouil Benetos and Holger Kirchhoff and Simon Dixon},
      year={2024},
      eprint={2407.04822},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2407.04822}, 
}

@book{1953fundamentals,
  title={Fundamentals of Telephony},
  url={https://books.google.no/books?id=8nvJ6qvtdPUC},
  year={1953},
  publisher={United States, Department of the Army}
}

@article{8454362,
  author={Chakravorty, Pragnan},
  journal={IEEE Signal Processing Magazine}, 
  title={What Is a Signal? [Lecture Notes]}, 
  year={2018},
  volume={35},
  number={5},
  pages={175-177},
  keywords={Signal processing;Antenna arrays;Spread spectrum communication;Image color analysis;Task analysis},
  doi={10.1109/MSP.2018.2832195}
}

@misc{oord2016wavenetgenerativemodelraw,
      title={WaveNet: A Generative Model for Raw Audio}, 
      author={Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
      year={2016},
      eprint={1609.03499},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1609.03499}, 
}

@dataset{gillet_2006_7432188,
  author       = {Gillet, Olivier and
                  Richard, Gaël},
  title        = {ENST-Drums: an extensive audio-visual database for
                   drum signals processing
                  },
  month        = oct,
  year         = 2006,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.7432188},
  url          = {https://doi.org/10.5281/zenodo.7432188},
}

@article{southall2017mdb,
  title={MDB Drums: An annotated subset of MedleyDB for automatic drum transcription},
  author={Southall, Carl and Wu, Chih-Wei and Lerch, Alexander and Hockman, Jason},
  year={2017}
}

@dataset{rachel_bittner_2014_1438309,
  author       = {Rachel Bittner and
                  Justin Salamon and
                  Mike Tierney and
                  Matthias Mauch and
                  Chris Cannam and
                  Juan Pablo Bello},
  title        = {MedleyDB Sample},
  month        = oct,
  year         = 2014,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.1438309},
  url          = {https://doi.org/10.5281/zenodo.1438309},
}

@article{pras2010sampling,
author={Pras Amandine and Guastavino Catherine},
journal={Journal of the Audio Engineering Society},
title={Sampling rate discrimination: 44.1 khz vs. 88.2 khz},
year={2010},
number={8101},
month={may},}

@misc{strang1993wavelettransformsversusfourier,
      title={Wavelet transforms versus Fourier transforms}, 
      author={Gilbert Strang},
      year={1993},
      eprint={math/9304214},
      archivePrefix={arXiv},
      primaryClass={math.NA},
      url={https://arxiv.org/abs/math/9304214}, 
}

@article{d3ea2d52-5ab2-3128-8b80-efb85267295d,
 ISSN = {00255718, 10886842},
 URL = {http://www.jstor.org/stable/2003354},
 author = {James W. Cooley and John W. Tukey},
 journal = {Mathematics of Computation},
 number = {90},
 pages = {297--301},
 publisher = {American Mathematical Society},
 title = {An Algorithm for the Machine Calculation of Complex Fourier Series},
 urldate = {2025-04-01},
 volume = {19},
 year = {1965}
}

@ARTICLE{1164317,
  author={Griffin, D. and Jae Lim},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Signal estimation from modified short-time Fourier transform}, 
  year={1984},
  volume={32},
  number={2},
  pages={236-243},
  keywords={Fourier transforms;Iterative algorithms;Discrete Fourier transforms;Speech enhancement;Hardware;Signal processing;Degradation;Estimation theory;Monitoring;Sampling methods},
  doi={10.1109/TASSP.1984.1164317}}

@article{5c874280-b9b4-3490-886e-70aef7a6c0f2,
 ISSN = {00222909},
 URL = {http://www.jstor.org/stable/843164},
 author = {Paul Pedersen},
 journal = {Journal of Music Theory},
 number = {2},
 pages = {295--308},
 publisher = {[Duke University Press, Yale University Department of Music]},
 title = {The Mel Scale},
 urldate = {2025-04-02},
 volume = {9},
 year = {1965}
}

@misc{wolfmonheim2024spectralrhythmfeaturesaudio,
      title={Spectral and Rhythm Features for Audio Classification with Deep Convolutional Neural Networks}, 
      author={Friedrich Wolf-Monheim},
      year={2024},
      eprint={2410.06927},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2410.06927}, 
}

@misc{gardner2022mt3multitaskmultitrackmusic,
      title={MT3: Multi-Task Multitrack Music Transcription}, 
      author={Josh Gardner and Ian Simon and Ethan Manilow and Curtis Hawthorne and Jesse Engel},
      year={2022},
      eprint={2111.03017},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2111.03017}, 
}

@misc{gong2021astaudiospectrogramtransformer,
      title={AST: Audio Spectrogram Transformer}, 
      author={Yuan Gong and Yu-An Chung and James Glass},
      year={2021},
      eprint={2104.01778},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2104.01778}, 
}

@inproceedings{Southall2016AutomaticDT,
  title={Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks},
  author={Carl Southall and Ryan Stables and Jason Hockman},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:2891003}
}

@inproceedings{inproceedings,
author = {Vogl, Richard and Dorfer, Matthias and Knees, Peter},
year = {2016},
month = {08},
pages = {},
title = {Recurrent Neural Networks for Drum Transcription}
}

@inproceedings{Bck2012EvaluatingTO,
  title={Evaluating the Online Capabilities of Onset Detection Methods},
  author={Sebastian B{\"o}ck and Florian Krebs and Markus Schedl},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:7379180}
}

@book{TheDrumHandbook2003,
  author = {Nicholls, Geoff},
  editor = {},
  publisher = {San Francisco, CA: Backbeat Books},
  title = {The Drum Handbook: Buying, maintaining, and getting the best from your drum kit},
  year = {2003}
}

@article{10.1162/neco.1997.9.8.1735,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{DBLP:conf/emnlp/ChoMGBBSB14,
  author       = {Kyunghyun Cho and
                  Bart van Merrienboer and
                  {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
                  Dzmitry Bahdanau and
                  Fethi Bougares and
                  Holger Schwenk and
                  Yoshua Bengio},
  editor       = {Alessandro Moschitti and
                  Bo Pang and
                  Walter Daelemans},
  title        = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
                  Machine Translation},
  booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2014, October 25-29, 2014, Doha, Qatar,
                  {A} meeting of SIGDAT, a Special Interest Group of the {ACL}},
  pages        = {1724--1734},
  publisher    = {{ACL}},
  year         = {2014},
  url          = {https://doi.org/10.3115/v1/d14-1179},
  doi          = {10.3115/V1/D14-1179},
  timestamp    = {Sun, 06 Oct 2024 21:00:49 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/ChoMGBBSB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}
