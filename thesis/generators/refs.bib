@INPROCEEDINGS{8937170,
  author={Manilow, Ethan and Wichern, Gordon and Seetharaman, Prem and Le Roux, Jonathan},
  booktitle={2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}, 
  title={Cutting Music Source Separation Some Slakh: A Dataset to Study the Impact of Training Data Quality and Quantity}, 
  year={2019},
  volume={},
  number={},
  pages={45-49},
  keywords={Training;Source separation;Instruments;Training data;Music;Tools;Multiple signal classification;music source separation;sample-based virtual instruments;synthesis;MIDI},
  doi={10.1109/WASPAA.2019.8937170}}

@book{raffel2016learning,
  title={Learning-based methods for comparing sequences, with applications to audio-to-midi alignment and matching},
  author={Raffel, Colin},
  year={2016},
  publisher={Columbia University}
}

@misc{callender2020improvingperceptualqualitydrum,
      title={Improving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset}, 
      author={Lee Callender and Curtis Hawthorne and Jesse Engel},
      year={2020},
      eprint={2004.00188},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2004.00188}, 
}

@misc{vogl2018multiinstrumentdrumtranscription,
      title={Towards multi-instrument drum transcription}, 
      author={Richard Vogl and Gerhard Widmer and Peter Knees},
      year={2018},
      eprint={1806.06676},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1806.06676}, 
}

@article{8350302,
  author={Wu, Chih-Wei and Dittmar, Christian and Southall, Carl and Vogl, Richard and Widmer, Gerhard and Hockman, Jason and Müller, Meinard and Lerch, Alexander},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={A Review of Automatic Drum Transcription}, 
  year={2018},
  volume={26},
  number={9},
  pages={1457-1483},
  keywords={Instruments;Task analysis;Speech processing;Spectrogram;Transient analysis;Rhythm;Music information retrieval;automatic music transcription;automatic drum transcription;machine learning;matrix factorization;deep learning},
  doi={10.1109/TASLP.2018.2830113}
}


@Article{signals4040042,
AUTHOR = {Zehren, Mickaël and Alunno, Marco and Bientinesi, Paolo},
TITLE = {High-Quality and Reproducible Automatic Drum Transcription from Crowdsourced Data},
JOURNAL = {Signals},
VOLUME = {4},
YEAR = {2023},
NUMBER = {4},
PAGES = {768--787},
URL = {https://www.mdpi.com/2624-6120/4/4/42},
ISSN = {2624-6120},
ABSTRACT = {Within the broad problem known as automatic music transcription, we considered the specific task of automatic drum transcription (ADT). This is a complex task that has recently shown significant advances thanks to deep learning (DL) techniques. Most notably, massive amounts of labeled data obtained from crowds of annotators have made it possible to implement large-scale supervised learning architectures for ADT. In this study, we explored the untapped potential of these new datasets by addressing three key points: First, we reviewed recent trends in DL architectures and focused on two techniques, self-attention mechanisms and tatum-synchronous convolutions. Then, to mitigate the noise and bias that are inherent in crowdsourced data, we extended the training data with additional annotations. Finally, to quantify the potential of the data, we compared many training scenarios by combining up to six different datasets, including zero-shot evaluations. Our findings revealed that crowdsourced datasets outperform previously utilized datasets, and regardless of the DL architecture employed, they are sufficient in size and quality to train accurate models. By fully exploiting this data source, our models produced high-quality drum transcriptions, achieving state-of-the-art results. Thanks to this accuracy, our work can be more successfully used by musicians (e.g., to learn new musical pieces by reading, or to convert their performances to MIDI) and researchers in music information retrieval (e.g., to retrieve information from the notes instead of audio, such as the rhythm or structure of a piece).},
DOI = {10.3390/signals4040042}
}

@inproceedings{Vogl2017DrumTV,
  title={Drum Transcription via Joint Beat and Drum Modeling Using Convolutional Recurrent Neural Networks},
  author={Richard Vogl and Matthias Dorfer and Gerhard Widmer and Peter Knees},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:21314796}
}

@misc{zehren2024analyzingreducingsynthetictorealtransfer,
      title={Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription}, 
      author={Mickaël Zehren and Marco Alunno and Paolo Bientinesi},
      year={2024},
      eprint={2407.19823},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2407.19823}, 
}

@inproceedings{chang2024yourmt3+,
  title={YourMT3+: Multi-Instrument Music Transcription with Enhanced Transformer Architectures and Cross-Dataset STEM Augmentation},
  author={Chang, Sungkyun and Benetos, Emmanouil and Kirchhoff, Holger and Dixon, Simon},
  booktitle={2024 IEEE 34th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

@book{1953fundamentals,
  title={Fundamentals of Telephony},
  url={https://books.google.no/books?id=8nvJ6qvtdPUC},
  year={1953},
  publisher={United States, Department of the Army}
}

@article{8454362,
  author={Chakravorty, Pragnan},
  journal={IEEE Signal Processing Magazine}, 
  title={What Is a Signal? [Lecture Notes]}, 
  year={2018},
  volume={35},
  number={5},
  pages={175-177},
  keywords={Signal processing;Antenna arrays;Spread spectrum communication;Image color analysis;Task analysis},
  doi={10.1109/MSP.2018.2832195},
  publisher={IEEE}
}

@misc{oord2016wavenetgenerativemodelraw,
      title={WaveNet: A Generative Model for Raw Audio}, 
      author={Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
      year={2016},
      eprint={1609.03499},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/1609.03499}, 
}

@inproceedings{gillet2006enst,
  title={Enst-drums: an extensive audio-visual database for drum signals processing},
  author={Gillet, Olivier and Richard, Ga{\"e}l},
  booktitle={International Society for Music Information Retrieval Conference (ISMIR)},
  year={2006}
}

@article{southall2017mdb,
  title={MDB Drums: An annotated subset of MedleyDB for automatic drum transcription},
  author={Southall, Carl and Wu, Chih-Wei and Lerch, Alexander and Hockman, Jason},
  year={2017}
}

@inproceedings{bittner2014medleydb,
  title={Medleydb: A multitrack dataset for annotation-intensive mir research.},
  author={Bittner, Rachel M and Salamon, Justin and Tierney, Mike and Mauch, Matthias and Cannam, Chris and Bello, Juan Pablo},
  booktitle={Ismir},
  volume={14},
  pages={155--160},
  year={2014}
}

@article{pras2010sampling,
author={Pras Amandine and Guastavino Catherine},
journal={Journal of the Audio Engineering Society},
title={Sampling rate discrimination: 44.1 khz vs. 88.2 khz},
year={2010},
number={8101},
month={may},}

@article{strang1993wavelet,
  title={Wavelet transforms versus Fourier transforms},
  author={Strang, Gilbert},
  journal={Bulletin of the American Mathematical Society},
  volume={28},
  number={2},
  pages={288--305},
  year={1993}
}

@article{d3ea2d52-5ab2-3128-8b80-efb85267295d,
 ISSN = {00255718, 10886842},
 URL = {http://www.jstor.org/stable/2003354},
 author = {James W. Cooley and John W. Tukey},
 journal = {Mathematics of Computation},
 number = {90},
 pages = {297--301},
 publisher = {American Mathematical Society},
 title = {An Algorithm for the Machine Calculation of Complex Fourier Series},
 urldate = {2025-04-01},
 volume = {19},
 year = {1965}
}

@ARTICLE{1164317,
  author={Griffin, D. and Jae Lim},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Signal estimation from modified short-time Fourier transform}, 
  year={1984},
  volume={32},
  number={2},
  pages={236-243},
  keywords={Fourier transforms;Iterative algorithms;Discrete Fourier transforms;Speech enhancement;Hardware;Signal processing;Degradation;Estimation theory;Monitoring;Sampling methods},
  doi={10.1109/TASSP.1984.1164317}}

@article{5c874280-b9b4-3490-886e-70aef7a6c0f2,
 ISSN = {00222909},
 URL = {http://www.jstor.org/stable/843164},
 author = {Paul Pedersen},
 journal = {Journal of Music Theory},
 number = {2},
 pages = {295--308},
 publisher = {[Duke University Press, Yale University Department of Music]},
 title = {The Mel Scale},
 urldate = {2025-04-02},
 volume = {9},
 year = {1965}
}

@misc{wolfmonheim2024spectralrhythmfeaturesaudio,
      title={Spectral and Rhythm Features for Audio Classification with Deep Convolutional Neural Networks}, 
      author={Friedrich Wolf-Monheim},
      year={2024},
      eprint={2410.06927},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2410.06927}, 
}

@article{jia2019deep,
  title={Deep learning-based automatic downbeat tracking: a brief review},
  author={Jia, Bijue and Lv, Jiancheng and Liu, Dayiheng},
  journal={Multimedia Systems},
  volume={25},
  number={6},
  pages={617--638},
  year={2019},
  publisher={Springer}
}

@misc{gardner2022mt3multitaskmultitrackmusic,
      title={MT3: Multi-Task Multitrack Music Transcription}, 
      author={Josh Gardner and Ian Simon and Ethan Manilow and Curtis Hawthorne and Jesse Engel},
      year={2022},
      eprint={2111.03017},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2111.03017}, 
}

@misc{gong2021astaudiospectrogramtransformer,
      title={AST: Audio Spectrogram Transformer}, 
      author={Yuan Gong and Yu-An Chung and James Glass},
      year={2021},
      eprint={2104.01778},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2104.01778}, 
}

@inproceedings{Southall2016AutomaticDT,
  title={Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks},
  author={Carl Southall and Ryan Stables and Jason Hockman},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:2891003}
}

@inproceedings{vogl2016recurrent,
  title={Recurrent Neural Networks for Drum Transcription.},
  author={Vogl, Richard and Dorfer, Matthias and Knees, Peter},
  booktitle={ISMIR},
  pages={730--736},
  year={2016}
}

@inproceedings{Bck2012EvaluatingTO,
  title={Evaluating the Online Capabilities of Onset Detection Methods},
  author={Sebastian B{\"o}ck and Florian Krebs and Markus Schedl},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:7379180}
}

@book{TheDrumHandbook2003,
  author = {Nicholls, Geoff},
  editor = {},
  publisher = {San Francisco, CA: Backbeat Books},
  title = {The Drum Handbook: Buying, maintaining, and getting the best from your drum kit},
  year = {2003}
}

@INPROCEEDINGS{10095245,
  author={Leiber, Maxime and Marnissi, Yosra and Barrau, Axel and Badaoui, Mohammed El},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Differentiable Adaptive Short-Time Fourier Transform with Respect to the Window Length}, 
  year={2023},
  volume={},
  number={},
  pages={1--5},
  keywords={Vibrations;Time-frequency analysis;Fourier transforms;Signal processing;Acoustics;Transient analysis;Speech processing;Time-frequency;differentiable STFT;adaptive STFT;spectrogram;gradient descent},
  doi={10.1109/ICASSP49357.2023.10095245}}


@article{10.1162/neco.1997.9.8.1735,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{DBLP:conf/emnlp/ChoMGBBSB14,
  author       = {Kyunghyun Cho and
                  Bart van Merrienboer and
                  {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
                  Dzmitry Bahdanau and
                  Fethi Bougares and
                  Holger Schwenk and
                  Yoshua Bengio},
  editor       = {Alessandro Moschitti and
                  Bo Pang and
                  Walter Daelemans},
  title        = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
                  Machine Translation},
  booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2014, October 25-29, 2014, Doha, Qatar,
                  {A} meeting of SIGDAT, a Special Interest Group of the {ACL}},
  pages        = {1724--1734},
  publisher    = {{ACL}},
  year         = {2014},
  url          = {https://doi.org/10.3115/v1/d14-1179},
  doi          = {10.3115/V1/D14-1179},
  timestamp    = {Sun, 06 Oct 2024 21:00:49 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/ChoMGBBSB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{gulati2020conformerconvolutionaugmentedtransformerspeech,
      title={Conformer: Convolution-augmented Transformer for Speech Recognition}, 
      author={Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
      year={2020},
      eprint={2005.08100},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2005.08100}, 
}


@InProceedings{pmlr-v119-xiong20b,
  title = 	 {On Layer Normalization in the Transformer Architecture},
  author =       {Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10524--10533},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf},
  url = 	 {https://proceedings.mlr.press/v119/xiong20b.html},
  abstract = 	 {The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}

@misc{hendrycks2023gaussianerrorlinearunits,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2023},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1606.08415}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}


@InProceedings{pmlr-v97-gillick19a,
  title = 	 {Learning to Groove with Inverse Sequence Transformations},
  author =       {Gillick, Jon and Roberts, Adam and Engel, Jesse and Eck, Douglas and Bamman, David},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2269--2279},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/gillick19a/gillick19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/gillick19a.html},
  abstract = 	 {We explore models for translating abstract musical ideas (scores, rhythms) into expressive performances using seq2seq and recurrent variational information bottleneck (VIB) models. Though seq2seq models usually require painstakingly aligned corpora, we show that it is possible to adapt an approach from the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix, Vid2Vid) to sequences, creating large volumes of paired data by performing simple transformations and training generative models to plausibly invert these transformations. Music, and drumming in particular, provides a strong test case for this approach because many common transformations (quantization, removing voices) have clear semantics, and learning to invert them has real-world applications. Focusing on the case of drum set players, we create and release a new dataset for this purpose, containing over 13 hours of recordings by professional drummers aligned with fine-grained timing and dynamics information. We also explore some of the creative potential of these models, demonstrating improvements on state-of-the-art methods for Humanization (instantiating a performance from a musical score).}
}

@mastersthesis{holz2021automatic,
  title={Automatic drum transcription with deep neural networks},
  author={Holz, Thomas},
  year={2021},
  school={Technische Universitaet Berlin (Germany)}
}

@INPROCEEDINGS{9747048,
  author={Hung, Yun-Ning and Wang, Ju-Chiang and Song, Xuchen and Lu, Wei-Tsung and Won, Minz},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Modeling Beats and Downbeats with a Time-Frequency Transformer}, 
  year={2022},
  volume={},
  number={},
  pages={401-405},
  keywords={Deep learning;Time-frequency analysis;Convolution;Neural networks;Transformers;Harmonic analysis;Natural language processing;Beat;Downbeat;Transformer;SpecTNT},
  doi={10.1109/ICASSP43922.2022.9747048}}

@ARTICLE{10056354,
  author={Huang, Lei and Qin, Jie and Zhou, Yi and Zhu, Fan and Liu, Li and Shao, Ling},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Normalization Techniques in Training DNNs: Methodology, Analysis and Application}, 
  year={2023},
  volume={45},
  number={8},
  pages={10173-10196},
  keywords={Training;Optimization;Covariance matrices;Task analysis;Tensors;Decorrelation;Biological neural networks;Batch normalization;deep neural networks;image classification;survey;weight normalization},
  doi={10.1109/TPAMI.2023.3250241}}

@inproceedings{cartwright2018increasing,
  title={Increasing drum transcription vocabulary using data synthesis},
  author={Cartwright, Mark and Bello, Juan Pablo},
  booktitle={Proc. International Conference on Digital Audio Effects (DAFx)},
  pages={72--79},
  year={2018}
}

@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@misc{ruder2017overviewgradientdescentoptimization,
      title={An overview of gradient descent optimization algorithms}, 
      author={Sebastian Ruder},
      year={2017},
      eprint={1609.04747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1609.04747}, 
}

@inproceedings{schluter2014improved,
  title={Improved musical onset detection with convolutional neural networks},
  author={Schl{\"u}ter, Jan and B{\"o}ck, Sebastian},
  booktitle={2014 ieee international conference on acoustics, speech and signal processing (icassp)},
  pages={6979--6983},
  year={2014},
  organization={IEEE}
}

@inproceedings{bock2016joint,
  title={Joint Beat and Downbeat Tracking with Recurrent Neural Networks.},
  author={B{\"o}ck, Sebastian and Krebs, Florian and Widmer, Gerhard},
  booktitle={ISMIR},
  pages={255--261},
  year={2016},
  organization={New York City}
}

@misc{bock2018improvementconvergenceproofadamoptimizer,
      title={An improvement of the convergence proof of the ADAM-Optimizer}, 
      author={Sebastian Bock and Josef Goppold and Martin Weiß},
      year={2018},
      eprint={1804.10587},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1804.10587}, 
}

@misc{loshchilov2019decoupledweightdecayregularization,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@inproceedings{akiba2019optuna,
  title={Optuna: A next-generation hyperparameter optimization framework},
  author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={2623--2631},
  year={2019}
}

@inproceedings{shekhar2021comparative,
  title={A comparative study of hyper-parameter optimization tools},
  author={Shekhar, Shashank and Bansode, Adesh and Salim, Asif},
  booktitle={2021 IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@misc{liaw2018tuneresearchplatformdistributed,
      title={Tune: A Research Platform for Distributed Model Selection and Training}, 
      author={Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E. Gonzalez and Ion Stoica},
      year={2018},
      eprint={1807.05118},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.05118}, 
}

@misc{raschka2020modelevaluationmodelselection,
      title={Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning}, 
      author={Sebastian Raschka},
      year={2020},
      eprint={1811.12808},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.12808}, 
}



@misc{roland_drum_midi_td_17, 
  url={https://support.roland.com/hc/en-us/articles/360005173411-TD-17-Default-Factory-MIDI-Note-Map}, 
  journal={https://support.roland.com/hc/en-us}, 
  publisher={Roland}, 
  title={TD-17: Default (Factory) MIDI Note Map},
  year={2022}
} 

@inproceedings{rothstein1995midi,
  title={MIDI: A comprehensive introduction},
  author={Rothstein, Joseph},
  volume={7},
  pages={59},
  year={1995},
  publisher={AR Editions, Inc.},
}

@phdthesis{10.5555/15202,
author = {Piszczalski, Martin},
title = {A computational model of music transcription},
year = {1986},
publisher = {University of Michigan},
address = {USA},
abstract = {The purpose of this research was to create a computational model of music transcription. The computer system that resulted processed natural musical sounds and automatically produced the music notation symbols that represented those sounds. The learned, human skill of transcribing music is one of the most sophisticated auditory-based pattern-recognition tasks that humans perform. Two related signal-to-symbol, machine-perception disciplines are automatic speech recognition and computer vision. In the computational-model approach, hypotheses are implemented in precise algorithmic form on the computer. Any single algorithm, in turn, must work in harmony with a constellation of other algorithms that together form the integrated system. The robustness of the system was tested using unconstrained music played on a variety of musical instruments.A bottom-up (i.e., data-driven) approach was implemented in this working system. The digitized sound signal from monophonic (one-part) music was first transformed into its spectral representation, forming the basis for extracting the time-varying partials. Next the time-varying pitch was established from these partials. Musical note segmentation was done via pitch and amplitude edge operators processing the pitch information. The discrete acoustical events thus produced were then classified into music-notation note symbols (representing pitch and duration). Last, the musical information was presented in the graphical printed form of music familiar to millions of musicians.The backbone of the system was in the pitch-detection/note segmentation method. Highly precise pitch tracking was found not to be necessary although context was important in determining the time-varying pitch.The automatic transcription system yielded notation that closely followed the original music performance. Additional research is necessary to incorporate higher-level musical knowledge that appears essential for the proper presentation of music notation. Other more ambitious goals include automatic polyphonic music transcription.},
note = {UMI order no. GAX86-21354}
}

@article{piszczalski1977automatic,
  title={Automatic music transcription},
  author={Piszczalski, Martin and Galler, Bernard A},
  journal={Computer Music Journal},
  pages={24--31},
  year={1977},
  publisher={JSTOR}
}

@article{jamshidi2024machine,
  title={Machine learning techniques in automatic music transcription: A systematic survey},
  author={Jamshidi, Fatemeh and Pike, Gary and Das, Amit and Chapman, Richard},
  journal={arXiv preprint arXiv:2406.15249},
  year={2024}
}

@inbook{starostenko2019,
author = {Starostenko, Oleg and Lopez-Rincon, Omar},
year = {2019},
month = {03},
pages = {127},
title = {A 3D Spatial Visualization of Measures in Music Compositions}
}

@dataset{zehren_2023_10084511,
  author       = {Zehren, Mickael and
                  Alunno, Marco and
                  Bientinesi, Paolo},
  title        = {ADTOF datasets},
  month        = nov,
  year         = 2023,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.10084511},
  url          = {https://doi.org/10.5281/zenodo.10084511},
  note         = {Accessed: 23.10.2024}
}

@dataset{gillet_2006_7432188,
  author       = {Gillet, Olivier and
                  Richard, Gaël},
  title        = {ENST-Drums: an extensive audio-visual database for
                   drum signals processing
                  },
  month        = oct,
  year         = 2006,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.7432188},
  url          = {https://doi.org/10.5281/zenodo.7432188},
  note         = {Accessed: 05.03.2025}
}

@dataset{southall_mdbdrums_2017,
  author = {Southall, Carl and Wu, Chih-Wei and Lerch, Alexander and Hockman, Jason},
  title = {MDB Drums},
  year = {2017},
  publisher = {GitHub},
  url={https://github.com/CarlSouthall/MDBDrums},
  note = {Accessed: 22.04.2025}
}

@dataset{callender_2020_4300943,
  author       = {Callender, Lee and
                  Hawthorne, Curtis and
                  Engel, Jesse},
  title        = {Expanded Groove MIDI Dataset},
  month        = apr,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {1.0.0},
  doi          = {10.5281/zenodo.4300943},
  url          = {https://doi.org/10.5281/zenodo.4300943},
  note         = {Accessed: 05.03.2025}
}

@dataset{manilow_2019_4599666,
  author       = {Manilow, Ethan and
                  Wichern, Gordon and
                  Seetharaman, Prem and
                  Le Roux, Jonathan},
  title        = {Slakh2100},
  month        = oct,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {slack2100-redux},
  doi          = {10.5281/zenodo.4599666},
  url          = {https://doi.org/10.5281/zenodo.4599666},
  note         = {Accessed: 17.04.2025}
}

@dataset{fosse_sadtp_2025,
  author = {Fosse, Runar},
  title = {SADTP},
  year = {2025},
  publisher = {GitHub},
  url={https://github.com/RunarFosse/SADTP},
  note = {Accessed: 16.06.2025},
}